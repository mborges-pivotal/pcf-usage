{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to process pcfusage.sh script\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "##########################################################\n",
    "# Looking to build more interactive dashboard\n",
    "# TODO: Allow interactive analysis and report generation\n",
    "##########################################################\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "##########################################################\n",
    "# Sample files capture by the pcfusage.sh script\n",
    "# TODO: Add this information in a metadata section\n",
    "# NOTE: Make sure the capture_date is expressed in the same\n",
    "#       timezone as the foundation on which this script was\n",
    "#       run or your application ages won't be correct.\n",
    "##########################################################\n",
    "\n",
    "# BORGESCLOUD File\n",
    "# file = \"/Users/mborges/Tools/PCF/scripts/dev_foundation.json\"\n",
    "# capture_date = datetime.datetime(2018, 6, 26, 0, 0)\n",
    "# diego_cell = {\"number_of\": 4, \"vcpu\": 4, \"ram_gb\": 32, \"disk_gb\": 32 }\n",
    "\n",
    "# Sample 1\n",
    "# file = \"/Users/mborges/Tools/PCF/scripts/samples/sample1_foundation.json\"\n",
    "# capture_date = datetime.datetime(2018, 7, 2, 22, 0)\n",
    "# diego_cell = {\"number_of\": 8, \"vcpu\": 8, \"ram_gb\": 32, \"disk_gb\": 256 }\n",
    "\n",
    "# Sample 2\n",
    "# file = \"/Users/mborges/Tools/PCF/scripts/samples/sample2_foundation.json\"\n",
    "# capture_date = datetime.datetime(2018, 7, 4, 22, 0)\n",
    "# diego_cell = {\"number_of\": 6, \"vcpu\": 4, \"ram_gb\": 30.5, \"disk_gb\": 128 }\n",
    "\n",
    "# Sample 3\n",
    "# file = \"/Users/mborges/Tools/PCF/scripts/samples/technipfmc_foundation.json\"\n",
    "# capture_date = datetime.datetime(2018, 7, 4, 22, 0)\n",
    "# diego_cell = {\"number_of\": 6, \"vcpu\": 4, \"ram_gb\": 30.5, \"disk_gb\": 128, \"operators\": 0.1}\n",
    "\n",
    "# Sample 4\n",
    "# file = \"/Users/mborges/Tools/PCF/scripts/samples/aa_dev_foundation.json\"\n",
    "# capture_date = datetime.datetime(2018, 7, 31, 22, 0)\n",
    "# diego_cell = {\"number_of\": 31, \"vcpu\": 8, \"ram_gb\": 16, \"disk_gb\": 160, \"operators\": 2}\n",
    "\n",
    "##########################################################\n",
    "# Pre-processing of the foundation.json file\n",
    "##########################################################\n",
    "\n",
    "# Know system orgs we used to remove system applications from our analysis\n",
    "system_orgs = [\"system\", \"p-dataflow\", \"p-spring-cloud-services\"]\n",
    "\n",
    "# Foundation capacity from metadata section (currently data above)\n",
    "total_vcpu = diego_cell['number_of'] * diego_cell['vcpu']\n",
    "total_memory = diego_cell['number_of'] * diego_cell['ram_gb']\n",
    "\n",
    "# Foundation json capture via script\n",
    "with open(file, \"r\") as read_file:\n",
    "    data = json.load(read_file)\n",
    "    \n",
    "# Process users dictionary    \n",
    "usersDict = data[5][\"users\"]\n",
    "    \n",
    "# Creating dataframes for specific sections\n",
    "# TODO: Can we not rely on the index? \n",
    "df_apps = pd.DataFrame(data[0][\"apps\"])\n",
    "df_orgs = pd.DataFrame(data[1][\"orgs\"])\n",
    "df_service_instances = pd.DataFrame(data[2][\"service_instances\"])\n",
    "df_services = pd.DataFrame(data[3][\"services\"])\n",
    "df_spaces = pd.DataFrame(data[4][\"spaces\"])\n",
    "df_users = pd.DataFrame(usersDict)\n",
    "\n",
    "# Fix column names so we can merge\n",
    "# TODO: Look inot fixing the pcfusage.sh script so this is not longer need\n",
    "df_orgs = df_orgs.rename(columns = {\"name\":\"org\"})\n",
    "df_spaces = df_spaces.rename(columns = {\"name\": \"space\", \"org\":\"org_guid\"})\n",
    "df_apps = df_apps.rename(columns = {\"space\": \"space_guid\"})\n",
    "\n",
    "# Merge spaces and orgs and create an non_system_spaces series\n",
    "environments = pd.merge(df_spaces, df_orgs, on=\"org_guid\")\n",
    "non_system_spaces = (environments['org'].isin(system_orgs))\n",
    "\n",
    "# Merge apps with spaces to get org and space names\n",
    "apps = pd.merge(df_apps, environments, on=\"space_guid\")\n",
    "\n",
    "apps = apps[apps.state != \"STOPPED\"]\n",
    "#display(apps)\n",
    "\n",
    "# consolidating buildpacks\n",
    "java_searchfor = ['client-certificate-mapper', 'container-', 'java', 'tc-']\n",
    "mask = apps['buildpack'].str.contains('|'.join(java_searchfor))\n",
    "apps.loc[mask, 'buildpack'] = 'java_buildpack_offline'\n",
    "\n",
    "dotnet_searchfor = ['netcore', 'dotnet', 'Core']\n",
    "mask = apps['buildpack'].str.contains('|'.join(dotnet_searchfor))\n",
    "apps.loc[mask, 'buildpack'] = 'dotnet-core_buildpack'\n",
    "\n",
    "static_searchfor = ['static', 'siteminder']\n",
    "mask = apps['buildpack'].str.contains('|'.join(static_searchfor))\n",
    "apps.loc[mask, 'buildpack'] = 'staticfile_buildpack'\n",
    "\n",
    "mask = apps['buildpack'].str.contains('node')\n",
    "apps.loc[mask, 'buildpack'] = 'nodejs_buildpack'\n",
    "\n",
    "mask = apps['buildpack'].str.contains('php')\n",
    "apps.loc[mask, 'buildpack'] = 'php_buildpack'\n",
    "\n",
    "\n",
    "# Merge services with service instances\n",
    "services = pd.merge(df_services, df_service_instances, on=\"service_guid\")\n",
    "\n",
    "# Non system applications\n",
    "#non_system_apps = (apps['org'] != 'system') & (apps['org'] != 'p-dataflow')\n",
    "system_apps = apps['org'].isin(system_orgs)\n",
    "non_system_apps = ~apps['org'].isin(system_orgs)\n",
    "\n",
    "# This is the core dataframe for applications\n",
    "df_non_system_apps = apps[non_system_apps]\n",
    "\n",
    "# Array of user objects\n",
    "# usersDict\n",
    "\n",
    "##########################################################\n",
    "# Functions\n",
    "##########################################################\n",
    "\n",
    "#d = datetime.datetime.strptime('2018-02-07T03:17:13Z', '%Y-%m-%dT%H:%M:%SZ')\n",
    "def get_days(last_updated):\n",
    "    deltatime = capture_date - datetime.datetime.strptime(last_updated, '%Y-%m-%dT%H:%M:%SZ')\n",
    "    return deltatime.days\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foundation by Numbers\n",
    "## speed\n",
    "Organizations can represent different business units, spaces environments where initial setup lead and process time are usually high. Services and buildpacks represents the middleware required to develop applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Orgs: {}\".format(len(df_non_system_apps['org_guid'].unique())))\n",
    "print (\"Spaces: {}\".format(len(df_non_system_apps['space_guid'].unique())))\n",
    "print (\"Users: {}\".format(len(df_users)))\n",
    "print (\"Services: {}\".format(len(df_services['label'].unique())))\n",
    "print (\"Unique Applications: {}\".format(len(df_non_system_apps['name'].unique())))\n",
    "print (\"Buildpacks: {}\".format(len(df_non_system_apps['buildpack'].unique())))\n",
    "print (\"Containers: {}\".format(df_non_system_apps['instances'].sum()))\n",
    "print (\"Service Instances: {}\".format(len(df_service_instances['name'].unique())))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application Instance Memory in MB\n",
    "## scalability\n",
    "Statistics on memory usage by all customer applications. This can show scalability of PCF by comparing min and max memory sizes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"{} unique non system apps using a total Memory: {}\".format(df_non_system_apps['name'].nunique(),df_non_system_apps['memory'].sum()))\n",
    "df_non_system_apps['memory'].describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Density\n",
    "## savings\n",
    "Number of containers per CPU and per vCPU. This can show infrastructure consolidation and savings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "containers_per_cell = apps[non_system_apps]['instances'].sum() / diego_cell['number_of']\n",
    "containers_per_vcpu = apps[non_system_apps]['instances'].sum() / total_vcpu\n",
    "print (\"Total system apps: {} and non system apps: {}\".format(apps[system_apps]['instances'].sum(), apps[non_system_apps]['instances'].sum()))\n",
    "print (\"containers_per_cell of non system apps {}\".format(containers_per_cell))\n",
    "print (\"containers_per_vcpu of non system apps {}\".format(containers_per_vcpu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application per Orgs\n",
    "This could provide a view into the different business units on the platform based on the nomenclature used. The more BUs the more compound value the platform can bring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab as plt\n",
    "#orgs = apps.groupby(\"org\").size()\n",
    "orgs = apps[non_system_apps].groupby(\"org\").size()\n",
    "print(orgs)\n",
    "\n",
    "\n",
    "# TODO merge this with days\n",
    "print(df_non_system_apps.groupby(\"org\")['space', 'name', 'buildpack'].nunique())\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "df_non_system_apps['days'] = df_non_system_apps['updated'].apply(get_days)\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    display(df_non_system_apps.groupby([\"org\",\"space\", \"name\", \"buildpack\"]).agg({'days': np.mean}))\n",
    "\n",
    "orgs.plot.barh(figsize=(15,15))\n",
    "\n",
    "plt.gca().spines[\"top\"].set_visible(False)  \n",
    "plt.gca().spines[\"right\"].set_visible(False)\n",
    "\n",
    "plt.ylabel('')\n",
    "plt.xlabel('Applications', fontsize=16)\n",
    "plt.ylabel('Organizations', fontsize=16)\n",
    "plt.xticks(fontsize=14)  \n",
    "plt.yticks(fontsize=14)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spaces = apps[non_system_apps].groupby(\"space\").size()\n",
    "spaces.plot.barh(figsize=(15,15))\n",
    "\n",
    "plt.gca().spines[\"top\"].set_visible(False)  \n",
    "plt.gca().spines[\"right\"].set_visible(False)\n",
    "\n",
    "plt.ylabel('')\n",
    "plt.xlabel('Applications', fontsize=16)\n",
    "plt.ylabel('Spaces', fontsize=16)\n",
    "plt.xticks(fontsize=14)  \n",
    "plt.yticks(fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Developer Productivity - Application vs Days\n",
    "## speed\n",
    "Here we explore when was an application last updated comparing with the date the data was capture to infer speed. We should see an increase of deployments due to the automation of the platform. We can possibly measure developer productivity by comparing with how long releases took in the past or testing methodologies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "\n",
    "\n",
    "# df_non_system_apps['days'] = df_non_system_apps['updated'].apply(get_days)\n",
    "app_days = df_non_system_apps['updated'].apply(get_days)\n",
    "\n",
    "\n",
    "#app_days.plot.hist(bins=50)\n",
    "N, bins, patches = plt.hist(app_days, 30, ec='k')\n",
    "\n",
    "cmap = plt.get_cmap('jet')\n",
    "hot = cmap(0.9)\n",
    "warm =cmap(0.7)\n",
    "cold = cmap(0.2)\n",
    "\n",
    "for i in range(0,7):\n",
    "    patches[i].set_facecolor(hot)\n",
    "for i in range(7,14):\n",
    "    patches[i].set_facecolor(warm)\n",
    "for i in range(14,30):\n",
    "    patches[i].set_facecolor(cold)\n",
    "\n",
    "#create legend\n",
    "handles = [Rectangle((0,0),1,1,color=c,ec=\"k\") for c in [hot,warm, cold]]\n",
    "labels= [\"hot\",\"warm\", \"cold\"]\n",
    "plt.legend(handles, labels)\n",
    "\n",
    "plt.xlabel('Days', fontsize=16)\n",
    "plt.ylabel('Applications', fontsize=16)\n",
    "plt.xticks(fontsize=14)  \n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "plt.gca().spines[\"top\"].set_visible(False)  \n",
    "plt.gca().spines[\"right\"].set_visible(False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_days.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Buildpack Distribution\n",
    "This provides an few of the languages and frameworks used in the platform. This can be used in regards to saving on middleware license and support. There is also day 2 ops concepts on maintaining current versions and consistently patching across environments. This is usually a subset of the available buildpack on PCF. We can talk about innovation and enabling multi-language for modern microservices based development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df_non_system_apps.groupby(\"buildpack\").size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches\n",
    "\n",
    "buildpacks = df_non_system_apps.groupby(\"buildpack\").size()\n",
    "\n",
    "# buildpacks.plot.pie(figsize=(20,20), title=\"Buildpack Distribution\")\n",
    "buildpacks.plot.pie(figsize=(15,15), autopct='%1.1f%%')\n",
    "\n",
    "plt.ylabel('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AI_memory = df_apps[\"memory\"].sum()\n",
    "AI_count = df_apps[\"instances\"].sum()\n",
    "unique_apps = len(apps['name'].unique())\n",
    "\n",
    "print(\"Total Apps is {}\".format(unique_apps))\n",
    "print(\"Total AIs: {} consuming {} MB RAM\".format(AI_count, AI_memory))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Services\n",
    "Fast provisioning of data services, platform services like autoscaler, SSO or batch are often not easy to manage. The concept of a marketplace is huge for developer velocity who usually have to wait to get access to RDBMS or messaging systems. A lot of value to explor here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pd.DataFrame(df_service_instances.groupby(\"service_guid\").size())\n",
    "\n",
    "service_usage = services.groupby('label').size()\n",
    "\n",
    "service_usage.plot.pie(figsize=(10,10))\n",
    "\n",
    "\n",
    "plt.ylabel('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive Analysis\n",
    "This is an attempt to create interactive dahsboards so we can better explorer value to various customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_apps.head()\n",
    "\n",
    "from ipywidgets import interactive\n",
    " \n",
    "items = ['All']+sorted(apps['org'].unique().tolist())\n",
    " \n",
    "def view(x=''):\n",
    "    if x=='All': \n",
    "        display(apps)\n",
    "    else:\n",
    "        result = apps[apps['org']==x] \n",
    "        print (\"Total Apps: {}\".format(result['instances'].count()))\n",
    "        display(result)\n",
    "\n",
    "w = widgets.Select(options=items)\n",
    "widgets.VBox([widgets.Label('Organizations'), interactive(view, x=w)])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
